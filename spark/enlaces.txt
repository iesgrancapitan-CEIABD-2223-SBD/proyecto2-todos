- como conectar mediante jdbc y pyspark en notebook o desde terminal

https://thucnc.medium.com/pyspark-in-jupyter-notebook-working-with-dataframe-jdbc-data-sources-6f3d39300bf6


- como poder parelizar en spark conexiones jbdc en workers

https://medium.com/mercedes-benz-techinnovation-blog/increasing-apache-spark-read-performance-for-jdbc-connections-a028115e20cd


- como usar la paralelización para extraer datos de una base de datos con pyspark.sql y jdbc desde varios workers:


https://medium.com/mercedes-benz-techinnovation-blog/increasing-apache-spark-read-performance-for-jdbc-connections-a028115e20cd


- mas sobre paralelización para extraer datos usando jdbc ( ojo el lenguaje de la web parece ser Scala )

https://dzlab.github.io/spark/2022/02/10/spark-jdbc-partitioning/


- ejemplo de uso de datos spotify para sistema de recomendaciones basado en pyspark y kafka

https://www.analyticsvidhya.com/blog/2021/06/spotify-recommendation-system-using-pyspark-and-kafka-streaming/

el dataset al que hace referencia en el artículo es un link roto, se puede encontrar aqui https://www.kaggle.com/datasets/mrmorj/dataset-of-songs-in-spotify


- diversas maneras de usar los jars en pyspark

https://sparkbyexamples.com/pyspark/how-to-add-multiple-jars-to-pyspark/



